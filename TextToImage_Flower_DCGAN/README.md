# Text To Image Synthesis Using DCGAN

![687474703a2f2f692e696d6775722e636f6d2f644e6c32486b5a2e6a7067](https://user-images.githubusercontent.com/70341313/146421547-28b1e428-8c14-4831-bb0e-e6ab5636519a.jpeg)

Image Source : Generative Adversarial Text-to-Image Synthesis Paper [link](https://arxiv.org/pdf/1605.05396.pdf)

Details of the Project Repository:
- DCGAN_Flower_Image.ipynb is the final notebook and the one that needs to be run and evaluated.
-  flowers.hdf5: These are the improved version of word2vec text embeddings for the text input data.
- The Notebook contains all the instructions to run the notebook. // Just Run all Cells
- checkpoints: This folder consists of the final generator and discriminator model after 100 Epochs of training and can be used as a pretrained model.
- results: This folder consists of images generated by dcgan on training, validation and test split.
-  epoch_loss.csv: This consists of the generator and discriminator losses for the number of training epochs.
